{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e3edeb4a-60b5-4d37-92a7-0910865dbd45"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Tokenize text to a new output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "42d1a7a2-7a58-4060-a510-b0efa6d5d3e1"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def change_rare_words(input_corp, output_corp, threshold = 5):\n",
    "    wordCounter = defaultdict(int)\n",
    "\n",
    "    with open(input_corp , 'r' , encoding = 'ISO-8859-1') as input_file:\n",
    "        for line in input_file:\n",
    "            for word in line.split():\n",
    "                wordCounter[word] += 1\n",
    "    \n",
    "    with open(input_corp, 'r' , encoding = 'ISO-8859-1') as input_file:\n",
    "        with open(output_corp , 'w') as output_file: \n",
    "            for line in input_file:\n",
    "                wordInLine = line.split()\n",
    "                for word in wordInLine:                    \n",
    "                    if wordCounter[word] < threshold:\n",
    "                        output_file.write('__RARE__' + ' ')\n",
    "                    else: \n",
    "                        output_file.write(word + ' ')\n",
    "                output_file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "33ccd1cc-c8b0-4838-9cbb-82e444aa653d"
    }
   },
   "source": [
    "Creates a dictionary from text (lowercase, numbers removed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "011f8422-aa27-4e83-a460-5604c498de63"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "import gzip\n",
    "\n",
    "LIMIT_OF_ROWS = 1000000\n",
    "\n",
    "def create_dictionary(corp_source, coding='utf-8' , write_to_file = False ,words_output = None):\n",
    "    pattern = re.compile('/^\\d*\\.?\\d*$/')\n",
    "    wordCounter = Counter()\n",
    "    limiter = 0\n",
    "    \n",
    "    print('Started creating dictionary.' + str(write_to_file) + ' ' + words_output)\n",
    "    with open(corp_source , 'r', encoding = coding, errors='ignore') as input_file:\n",
    "        for line in input_file:\n",
    "            limiter += 1\n",
    "            if limiter > LIMIT_OF_ROWS:\n",
    "                break;\n",
    "            for word in line.split():\n",
    "                if word=='__RARE__':\n",
    "                    wordCounter['__RARE__'] += 1\n",
    "                for p in string.punctuation:\n",
    "                    word = word.replace(p,\"\")\n",
    "                if pattern.match(word):\n",
    "                    wordCounter['__NUM__'] += 1\n",
    "                word = word.lower()\n",
    "                if word != '':\n",
    "                    wordCounter[word] += 1\n",
    "    \n",
    "    if write_to_file is True:\n",
    "        print('writing started.')\n",
    "        with open(words_output , 'w', encoding = coding) as wordsoutput:\n",
    "            for item in wordCounter.most_common():\n",
    "                wordsoutput.write(\"{0} \\t {1} \\n\".format(item[0] , item[1]))\n",
    "    \n",
    "    return wordCounter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "e48df6ac-8180-4829-9260-8068de261e7e"
    }
   },
   "source": [
    "Creates counter object from existing dictionary file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "a1493b4c-9caf-48f9-a5cc-d569c38fc62c"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "def create_counter_from_file(filename):\n",
    "    word_counter = Counter()\n",
    "    with open(filename, 'r') as input_file:\n",
    "        for line in input_file:\n",
    "            words = line.split('\\t')\n",
    "            word_counter[words[0]] = int(words[1])\n",
    "    return word_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "68876d5e-d99f-4785-b420-cdfbaa104483"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "7e4df678-015a-4af0-b278-785943355512"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "word_counter = create_dictionary('czech_tokenized' , 'czech_tok_words1')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started creating dictionary.True sk_dict_1.txt\n"
     ]
    }
   ],
   "source": [
    "def count_coverage(sample_dict, corp_dict):\n",
    "    good = 0\n",
    "    sum = 0\n",
    "    target_size = 0\n",
    "    for word in corp_dict.values():\n",
    "        target_size += word\n",
    "    \n",
    "    limits = [10,100,1000,10000,100000,1000000]\n",
    "    limit_index = 0\n",
    "    current = 0\n",
    "    for word in sample_dict.most_common():\n",
    "        if word[0] in corp_dict.keys():\n",
    "            good += word[1]\n",
    "        current += 1\n",
    "        if current > limits[limit_index]:\n",
    "            limit_index += 1\n",
    "            print('Current: ' + str(current) + ', words counted good: ' + str(good) + ' / ' + str(target_size) + ' , limit_index: ' + str(limit_index))\n",
    "            if limit_index == 6:\n",
    "                \n",
    "                break;\n",
    "\n",
    "word_counter = create_dictionary('europarl-v7.sk-en.sk', 'utf-8' , True, 'sk_dict_1.txt')\n",
    "print('Done with first.')\n",
    "print(word_counter.most_common(30))\n",
    "          \n",
    "word_counter2 = create_dictionary('slovak.tok' , 'utf-8', True, 'sk_dict_2.txt')\n",
    "print('Done with second.')\n",
    "print(word_counter2.most_common(30))\n",
    "\n",
    "\n",
    "#word_counter = create_counter_from_file('sk_dict_1.txt')\n",
    "#print(word_counter.most_common(3))\n",
    "#word_counter2 = create_counter_from_file('sk_dict_2.txt')\n",
    "#print(word_counter2.most_common(3))\n",
    "count_coverage(word_counter,word_counter2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbpresent": {
   "slides": {},
   "themes": {
    "default": "1194ff75-218f-411b-9ac4-7416ae18a807",
    "theme": {
     "1194ff75-218f-411b-9ac4-7416ae18a807": {
      "id": "1194ff75-218f-411b-9ac4-7416ae18a807",
      "palette": {
       "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
        "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "rgb": [
         252,
         252,
         252
        ]
       },
       "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
        "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "rgb": [
         68,
         68,
         68
        ]
       },
       "50f92c45-a630-455b-aec3-788680ec7410": {
        "id": "50f92c45-a630-455b-aec3-788680ec7410",
        "rgb": [
         155,
         177,
         192
        ]
       },
       "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
        "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "rgb": [
         43,
         126,
         184
        ]
       },
       "efa7f048-9acb-414c-8b04-a26811511a21": {
        "id": "efa7f048-9acb-414c-8b04-a26811511a21",
        "rgb": [
         25.118061674008803,
         73.60176211453744,
         107.4819383259912
        ]
       }
      },
      "rules": {
       "blockquote": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410"
       },
       "code": {
        "font-family": "Anonymous Pro"
       },
       "h1": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 8
       },
       "h2": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 6
       },
       "h3": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-family": "Lato",
        "font-size": 5.5
       },
       "h4": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 5
       },
       "h5": {
        "font-family": "Lato"
       },
       "h6": {
        "font-family": "Lato"
       },
       "h7": {
        "font-family": "Lato"
       },
       "pre": {
        "font-family": "Anonymous Pro",
        "font-size": 4
       }
      },
      "text-base": {
       "font-family": "Merriweather",
       "font-size": 4
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
